1.  Write a Python program that uses the HiveQL language to create a table named "Employees" with columns for "id," "name," and "salary."

from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to create the Employees table
create_table_query = """
CREATE TABLE Employees (
    id INT,
    name STRING,
    salary FLOAT
)
"""

# Execute the create table query
cursor.execute(create_table_query)

# Close the cursor and connection
cursor.close()
conn.close()


2.  Create a Python program that retrieves records from a Hive table named "Customers" where the age is greater than 30.


from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to retrieve records from the Customers table where age > 30
retrieve_records_query = """
SELECT *
FROM Customers
WHERE age > 30
"""

# Execute the retrieve records query
cursor.execute(retrieve_records_query)

# Fetch all the rows returned by the query
rows = cursor.fetchall()

# Print the retrieved records
for row in rows:
    print(row)

# Close the cursor and connection
cursor.close()
conn.close()


3.  Write a Python script that sorts records in descending order based on the "timestamp" column in a Hive table named "Logs."


from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to sort records in descending order based on timestamp
sort_records_query = """
SELECT *
FROM Logs
ORDER BY timestamp DESC
"""

# Execute the sort records query
cursor.execute(sort_records_query)

# Fetch all the rows returned by the query
rows = cursor.fetchall()

# Print the sorted records
for row in rows:
    print(row)

# Close the cursor and connection
cursor.close()
conn.close()



4.  Write a Python program that connects to a Hive server using PyHive library and retrieves all records from a table named "Products".


from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to retrieve all records from the Products table
retrieve_records_query = """
SELECT *
FROM Products
"""

# Execute the retrieve records query
cursor.execute(retrieve_records_query)

# Fetch all the rows returned by the query
rows = cursor.fetchall()

# Print the retrieved records
for row in rows:
    print(row)

# Close the cursor and connection
cursor.close()
conn.close()


5.  Write a Python script that calculates the average salary of employees from a Hive table named "Employees".


from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to calculate the average salary of employees
average_salary_query = """
SELECT AVG(salary) AS average_salary
FROM Employees
"""

# Execute the average salary query
cursor.execute(average_salary_query)

# Fetch the result of the query
result = cursor.fetchone()

# Extract the average salary value from the result
average_salary = result[0]

# Print the average salary
print("Average Salary: ", average_salary)

# Close the cursor and connection
cursor.close()
conn.close()


6.  Implement a Python program that uses Hive partitioning to create a partitioned table named "Sales_Data" based on the "year" and "month" columns.


from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to create a partitioned table named Sales_Data
create_table_query = """
CREATE TABLE Sales_Data (
    id INT,
    product STRING,
    sales FLOAT
)
PARTITIONED BY (year INT, month INT)
"""

# Execute the create table query
cursor.execute(create_table_query)

# Close the cursor and connection
cursor.close()
conn.close()


7.  Develop a Python script that adds a new column named "email" of type string to an existing Hive table named "Employees."


from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to add a new column named "email" to the Employees table
alter_table_query = """
ALTER TABLE Employees
ADD COLUMNS (email STRING)
"""

# Execute the alter table query
cursor.execute(alter_table_query)

# Close the cursor and connection
cursor.close()
conn.close()


8.  Create a Python program that performs an inner join between two Hive tables, "Orders" and "Customers," based on a common column.



from pyhive import hive

# Establish a connection to Hive
conn = hive.Connection(host='localhost', port=10000, username='your_username')

# Create a cursor object to execute Hive queries
cursor = conn.cursor()

# Define the HiveQL query to perform the inner join between Orders and Customers tables
inner_join_query = """
SELECT *
FROM Orders
INNER JOIN Customers ON Orders.customer_id = Customers.customer_id
"""

# Execute the inner join query
cursor.execute(inner_join_query)

# Fetch all the rows returned by the query
rows = cursor.fetchall()

# Print the joined records
for row in rows:
    print(row)

# Close the cursor and connection
cursor.close()
conn.close()


9.  Implement a Python program that uses the Hive SerDe library to process JSON data stored in a Hive table named "User_Activity_Logs."
